{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d895b4",
   "metadata": {},
   "source": [
    "Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8376367b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input matrices: 1\n",
      "Shape of first input matrix: (3887, 16483)\n",
      "Number of norm factors: 1\n",
      "Shape of first norm factor array: (3887,)\n",
      "First 5 norm factor values: [1. 1. 1. 1. 1.]\n",
      "Input distribution: ['G']\n",
      "Min value in X: 0.0\n",
      "Any negatives? 0\n",
      "Pyro version: 1.9.1\n",
      "Min: 0.0 Max: 74.91528 NaNs: 0\n",
      "Norm factors min: 1.0\n"
     ]
    }
   ],
   "source": [
    "import midaa as maa\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pyro\n",
    "\n",
    "# Load the real dataset\n",
    "adata_beta_hfd = sc.read_h5ad(r\"data/beta_cells_hfd.h5ad\")\n",
    "\n",
    "# Convert to MIDAA input\n",
    "input_matrix, norm_factors, input_distribution = maa.get_input_params_adata(adata_beta_hfd)\n",
    "\n",
    "# If you want to force RNA-seq likelihood, uncomment the next line:\n",
    "# input_distribution = [\"NB\"]\n",
    "\n",
    "# Check input matrix\n",
    "print(\"Number of input matrices:\", len(input_matrix))         # should be 1\n",
    "print(\"Shape of first input matrix:\", input_matrix[0].shape)  # e.g., (2638, 1838)\n",
    "\n",
    "# Check normalization factors\n",
    "print(\"Number of norm factors:\", len(norm_factors))\n",
    "print(\"Shape of first norm factor array:\", norm_factors[0].shape)\n",
    "print(\"First 5 norm factor values:\", norm_factors[0][:5])\n",
    "\n",
    "# Input distribution\n",
    "print(\"Input distribution:\", input_distribution)  # usually [\"NB\"] for RNA-seq\n",
    "\n",
    "# Convert sparse matrix to dense if needed\n",
    "X = input_matrix[0].A if hasattr(input_matrix[0], \"A\") else input_matrix[0]\n",
    "print(\"Min value in X:\", X.min())\n",
    "print(\"Any negatives?\", (X < 0).sum())\n",
    "\n",
    "# Pyro version\n",
    "print(\"Pyro version:\", pyro.__version__)  # should be 1.9.1\n",
    "\n",
    "# Extra checks\n",
    "print(\"Min:\", X.min(), \"Max:\", X.max(), \"NaNs:\", np.isnan(X).sum())\n",
    "print(\"Norm factors min:\", norm_factors[0].min())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08ac90",
   "metadata": {},
   "source": [
    "Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13172f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bar desc:   0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][compute_loss] n_input_matrices=1; sample_counts=[3887]; features=[16483]\n",
      "[DEBUG][compute_loss] sigma_0 shape=(3887, 16483) min=1 max=1 any_neg=False\n",
      "[DEBUG][compute_loss] n_input_matrices=1; sample_counts=[3887]; features=[16483]\n",
      "[DEBUG][compute_loss] sigma_0 shape=(3887, 16483) min=1 max=1 any_neg=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO: 128543032.00000  :   0%|          | 1/2000 [00:17<9:45:01, 17.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][compute_loss] n_input_matrices=1; sample_counts=[3887]; features=[16483]\n",
      "[DEBUG][compute_loss] sigma_0 shape=(3887, 16483) min=0.995018 max=1.00501 any_neg=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO: 125975520.00000  :   0%|          | 2/2000 [00:25<6:28:54, 11.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][compute_loss] n_input_matrices=1; sample_counts=[3887]; features=[16483]\n",
      "[DEBUG][compute_loss] sigma_0 shape=(3887, 16483) min=0.990067 max=1.01003 any_neg=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO: 124606304.00000  :   0%|          | 3/2000 [00:30<4:59:09,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG][compute_loss] n_input_matrices=1; sample_counts=[3887]; features=[16483]\n",
      "[DEBUG][compute_loss] sigma_0 shape=(3887, 16483) min=0.985146 max=1.01508 any_neg=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELBO: 124606304.00000  :   0%|          | 3/2000 [00:35<6:28:26, 11.67s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit MIDAA\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m aa_result \u001b[38;5;241m=\u001b[39m \u001b[43mmaa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_MIDAA\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_factors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_distribution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnarchetypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\midaa\\src\\midaa\\Interface.py:229\u001b[0m, in \u001b[0;36mfit_MIDAA\u001b[1;34m(input_matrix, normalization_factor, input_types, loss_weights_reconstruction, side_matrices, input_types_side, loss_weights_side, hidden_dims_dec_common, hidden_dims_dec_last, hidden_dims_dec_last_side, hidden_dims_enc_ind, hidden_dims_enc_common, hidden_dims_enc_pre_Z, layers_independent_types, layers_independent_types_side, image_size, narchetypes, model_matrix, just_VAE, linearize_encoder, linearize_decoder, VAE_steps, CUDA, lr, gamma_lr, steps, fix_Z, initialization_B_weight, Z_fix_norm, Z_fix_release_step, reconstruct_input_and_side, initialization_input, initialization_steps_phase_1, initialization_lr_phase_1, initialization_steps_phase_2, initialization_lr_phase_2, torch_seed, batch_size, kernel_size, stride, padding, pool_size, pool_stride)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     lrd \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 229\u001b[0m deepAA, elbo_list  \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeepAA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeepAA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43minput_matrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmodel_matrix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mnormalization_factor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnormalization_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mside_matrices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mside_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43minitialization_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitialization_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mloss_weights_reconstruction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_weights_reconstruction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mloss_weights_side\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_weights_side\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43minitialization_B_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitialization_B_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlrd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlrd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mVAE_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVAE_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_Z\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfix_Z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mZ_fix_release_step\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mZ_fix_release_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCUDA\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43musing_CUDA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m params_run \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    245\u001b[0m A,B,Z \u001b[38;5;241m=\u001b[39m deepAA\u001b[38;5;241m.\u001b[39mencoder(input_matrix)\n",
      "File \u001b[1;32m~\\midaa\\src\\midaa\\Interface.py:402\u001b[0m, in \u001b[0;36mtraining_loop\u001b[1;34m(deepAA, input_matrix, model_matrix, normalization_factor, side_matrices, initialization_input, loss_weights_reconstruction, loss_weights_side, initialization_B_weight, batch_size, lr, steps, lrd, VAE_steps, fix_Z, Z_fix_release_step, initialization_mode_step1, initialization_mode_step2, CUDA)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m#print(list(params)[1])\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;66;03m#print(list(params_old)[1])\u001b[39;00m\n\u001b[0;32m    399\u001b[0m elbo \u001b[38;5;241m=\u001b[39m loss_fn(deepAA\u001b[38;5;241m.\u001b[39mmodel, deepAA\u001b[38;5;241m.\u001b[39mguide, input_matrix_run, model_matrix_run, \n\u001b[0;32m    400\u001b[0m                   normalization_factor_run, side_matrices_run, loss_weights_reconstruction, \n\u001b[0;32m    401\u001b[0m                   loss_weights_side, initialization_input_run, initialization_B_weight)\n\u001b[1;32m--> 402\u001b[0m \u001b[43melbo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# take a step and zero the parameter gradients\u001b[39;00m\n\u001b[0;32m    404\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Manuel\\anaconda3_new\\envs\\MIDAA\\Lib\\site-packages\\torch\\_tensor.py:513\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor wrt graph leaves.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03mThe graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;124;03m        used to compute the attr::tensors.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_torch_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Manuel\\anaconda3_new\\envs\\MIDAA\\Lib\\site-packages\\torch\\overrides.py:1604\u001b[0m, in \u001b[0;36mhandle_torch_function\u001b[1;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_torch_function_mode_enabled():\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;66;03m# if we're here, the mode must be set to a TorchFunctionStackMode\u001b[39;00m\n\u001b[0;32m   1602\u001b[0m     \u001b[38;5;66;03m# this unsets it and calls directly into TorchFunctionStackMode's torch function\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _pop_mode_temporarily() \u001b[38;5;28;01mas\u001b[39;00m mode:\n\u001b[1;32m-> 1604\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpublic_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Manuel\\anaconda3_new\\envs\\MIDAA\\Lib\\site-packages\\torch\\utils\\_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[1;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manuel\\anaconda3_new\\envs\\MIDAA\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manuel\\anaconda3_new\\envs\\MIDAA\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Manuel\\anaconda3_new\\envs\\MIDAA\\Lib\\site-packages\\pyro\\util.py:84\u001b[0m, in \u001b[0;36mwarn_if_nan.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     80\u001b[0m         lineno \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_lineno\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(value) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m     83\u001b[0m     value\u001b[38;5;241m.\u001b[39mregister_hook(\n\u001b[1;32m---> 84\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: warn_if_nan(\n\u001b[0;32m     85\u001b[0m             x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg, filename\u001b[38;5;241m=\u001b[39mfilename, lineno\u001b[38;5;241m=\u001b[39mlineno\n\u001b[0;32m     86\u001b[0m         )\n\u001b[0;32m     87\u001b[0m     )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch_isnan(value):\n\u001b[0;32m     90\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn_explicit(\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered NaN\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m     93\u001b[0m         filename,\n\u001b[0;32m     94\u001b[0m         lineno,\n\u001b[0;32m     95\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fit MIDAA\n",
    "aa_result = maa.fit_MIDAA(\n",
    "    input_matrix,\n",
    "    norm_factors,\n",
    "    input_distribution,\n",
    "    narchetypes=4,\n",
    "    torch_seed=42,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827505c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27cc3a39",
   "metadata": {},
   "source": [
    "Look at code results and saving the matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfa762d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(A, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m A, B, Z, C, X, labels\n\u001b[1;32m---> 27\u001b[0m A, B, Z, C, X, labels \u001b[38;5;241m=\u001b[39m extract_mida_matrices(\u001b[43maa_result\u001b[49m, input_matrix)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA (memberships):\u001b[39m\u001b[38;5;124m\"\u001b[39m, A\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB (latent archetype coords):\u001b[39m\u001b[38;5;124m\"\u001b[39m, B\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aa_result' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_mida_matrices(aa_result, input_matrix):\n",
    "    iq = aa_result[\"inferred_quantities\"]\n",
    "\n",
    "    # A: (n_cells × n_archetypes)\n",
    "    A = iq[\"A\"]\n",
    "\n",
    "    # Z: latent representation (n_cells × latent_dim)\n",
    "    Z = iq[\"Z\"]\n",
    "\n",
    "    # B: archetype positions in latent space (n_archetypes × latent_dim)\n",
    "    B = iq[\"B\"]\n",
    "\n",
    "    # archetypes_inferred: gene weights for each archetype\n",
    "    # shape: (n_genes, n_archetypes)\n",
    "    C = iq[\"archetypes_inferred\"]\n",
    "\n",
    "    # X: original input data\n",
    "    X = input_matrix[0]   # (n_cells × n_genes)\n",
    "\n",
    "    # Labels = archetype with highest membership\n",
    "    labels = np.argmax(A, axis=1)\n",
    "\n",
    "    return A, B, Z, C, X, labels\n",
    "\n",
    "A, B, Z, C, X, labels = extract_mida_matrices(aa_result, input_matrix)\n",
    "\n",
    "print(\"A (memberships):\", A.shape)\n",
    "print(\"B (latent archetype coords):\", B.shape)\n",
    "print(\"Z (latent cells):\", Z.shape)\n",
    "print(\"C (gene weights):\", C.shape)\n",
    "print(\"X (input data):\", X.shape)\n",
    "print(\"labels:\", labels.shape)\n",
    "\n",
    "import torch\n",
    "\n",
    "# Save   three core MIDAA matrices\n",
    "torch.save(\n",
    "    {'A': A, 'B': B, 'C': C},\n",
    "    \"midaa_core_matrices.pth\"\n",
    ")\n",
    "\n",
    "print(\"Saved A, B, C matrices to midaa_core_matrices.pth\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "\n",
    "scatter = plt.scatter(\n",
    "    Z[:, 0], Z[:, 1],\n",
    "    c=labels,\n",
    "    s=10,\n",
    "    cmap=\"tab10\",       # better for discrete clusters\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "plt.title(\"MIDAA Latent Space (Z) — Cells Colored by Archetype\")\n",
    "plt.xlabel(\"Z1\")\n",
    "plt.ylabel(\"Z2\")\n",
    "\n",
    "# Create legend for 4 archetypes\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, [f\"Archetype {i}\" for i in range(4)], title=\"Archetypes\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIDAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
