{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runing the DEEP AA on the MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, torch, scprep\n",
    "sys.path.append('../')\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from AAnet_torch import *\n",
    "from torch import optim\n",
    "import torchvision; from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib; import matplotlib.pyplot as plt\n",
    "from AAnet_torch import models, utils, data, plot\n",
    "import os\n",
    "from scipy.spatial.distance import squareform, pdist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST...\n",
      "MNIST Loaded. Data shape: (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and Preprocess MNIST (The \"Binary\" way)\n",
    "print(\"Loading MNIST...\")\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.ToTensor()])\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "data_all = mnist.data.numpy()\n",
    "data_all = data_all / 255\n",
    "data_all = (data_all * 2) - 1 # norm\n",
    "labels = mnist.targets.numpy()\n",
    "\n",
    "print(\"MNIST Loaded. Data shape:\", data_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5842, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pick single digit\n",
    "digit = 4\n",
    "\n",
    "# Select data for the specified digit\n",
    "idx_digit = mnist.targets.numpy() == digit\n",
    "\n",
    "# Create dataset for the selected digit\n",
    "data_digit = data_all[idx_digit,]\n",
    "\n",
    "# Reshape data to 2D array (samples x features)\n",
    "data_digit = np.reshape(data_digit, (data_digit.shape[0], -1))\n",
    "\n",
    "# Print shape of the digit-specific dataset\n",
    "print(data_digit.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AAnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ARCHETYPES = 3\n",
    "N_RUNS = 5\n",
    "N_EPOCHS = 10      \n",
    "N_PROTOTYPES = 10     \n",
    "\n",
    "S_list = []\n",
    "C_list = []\n",
    "L_list = []  \n",
    "\n",
    "SAVE_DIR = 'results/MNIST_5runs'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(data_digit, batch_size=256, shuffle=True, num_workers=4)\n",
    "\n",
    "# Added a transposoition to ensure final shape\n",
    "X = torch.tensor(data_digit, dtype=torch.float64).transpose(0, 1)\n",
    "\n",
    "# Warm-start model with graph-based extrema for improved results\n",
    "extrema = torch.Tensor(utils.get_laplacian_extrema(data_digit, n_extrema=N_ARCHETYPES))\n",
    "extrema = torch.Tensor(data_digit[extrema.numpy().astype(int)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "model = models.AAnet_vanilla(noise=0.05, layer_widths=[256, 128],\n",
    "                             n_archetypes=N_ARCHETYPES, \n",
    "                             input_shape=data_digit.shape[1],\n",
    "                             device=device, diffusion_extrema=extrema)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run AAnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archetypal_embedding shape: (5842, 2)\n",
      "Run 1 - S shape: (3, 5842), C shape: (5842, 3), X shape: (5842, 784)\n",
      "Run 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archetypal_embedding shape: (5842, 2)\n",
      "Run 2 - S shape: (3, 5842), C shape: (5842, 3), X shape: (5842, 784)\n",
      "Run 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archetypal_embedding shape: (5842, 2)\n",
      "Run 3 - S shape: (3, 5842), C shape: (5842, 3), X shape: (5842, 784)\n",
      "Run 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archetypal_embedding shape: (5842, 2)\n",
      "Run 4 - S shape: (3, 5842), C shape: (5842, 3), X shape: (5842, 784)\n",
      "Run 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archetypal_embedding shape: (5842, 2)\n",
      "Run 5 - S shape: (3, 5842), C shape: (5842, 3), X shape: (5842, 784)\n",
      "✅ Saved all 5 runs results.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "S_list = []\n",
    "C_list = []\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    print(f\"Run {run+1}/{N_RUNS}\")\n",
    "\n",
    "    # Train for N_EPOCHS with progress bar\n",
    "    for epoch in trange(1, N_EPOCHS + 1, desc=f\"Training Run {run+1}\", leave=False):\n",
    "        loss, r_loss, a_loss = utils.train_epoch(model, data_loader, optimizer, epoch=epoch, gamma_extrema=1.0)\n",
    "    \n",
    "    # Encode final embeddings\n",
    "    archetypal_embedding = model.encode(torch.Tensor(data_digit)).detach().numpy()  # shape: (N_samples, k)\n",
    "    print(\"Archetypal_embedding shape:\", archetypal_embedding.shape)\n",
    "    \n",
    "    # Convert to barycentric coordinates\n",
    "    barycentric_embedding = model.euclidean_to_barycentric(torch.Tensor(archetypal_embedding)).detach().numpy()\n",
    "    \n",
    "    # S: (archetypes × samples)\n",
    "    S_T = barycentric_embedding.T          # shape: (archetypes, samples)\n",
    "    C = S_T.T                             # shape: (samples, archetypes)\n",
    "\n",
    "    S_list.append(S_T)\n",
    "    C_list.append(C)\n",
    "    \n",
    "    print(f\"Run {run+1} - S shape: {S_T.shape}, C shape: {C.shape}, X shape: {data_digit.shape}\")  \n",
    "\n",
    "    # Optional: save per run\n",
    "    np.savez(os.path.join(SAVE_DIR, f'run{run+1}_results.npz'), S=S_T, C=C, X=data_digit)\n",
    "\n",
    "# Save all runs together\n",
    "torch.save({'S_list': S_list, 'C_list': C_list, 'X': data_digit}, os.path.join(SAVE_DIR, 'mnist_aanet_aa_results.pth'))\n",
    "print(f\"✅ Saved all {N_RUNS} runs results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Results Keys: dict_keys(['S_list', 'C_list', 'X'])\n",
      "Number of Runs Saved: 5\n",
      "Shape of C in first run: (5842, 3)\n",
      "Shape of S in first run: (3, 5842)\n",
      "Shape of X in first run: (5842, 784)\n"
     ]
    }
   ],
   "source": [
    "# Open the saved results to verify\n",
    "results = torch.load('/Users/joaomata/Desktop/DTU/DeepLearning/ProjectDL/AAnet/example_notebooks/results/MNIST_5runs/mnist_aanet_aa_results.pth', weights_only=False)\n",
    "print(\"Saved Results Keys:\", results.keys())\n",
    "print(\"Number of Runs Saved:\", len(results['C_list']))\n",
    "\n",
    "# Print shapes if the first run to verify\n",
    "print(\"Shape of C in first run:\", results['C_list'][0].shape)\n",
    "print(\"Shape of S in first run:\", results['S_list'][0].shape)\n",
    "print('Shape of X in first run:', results['X'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        return tensor.detach().cpu().numpy()\n",
    "    return tensor\n",
    "\n",
    "def preprocess(X):\n",
    "    meanX = np.mean(X, axis=0)\n",
    "    X_centered = X - meanX\n",
    "    mSST = np.sum(np.mean(X_centered**2, axis=0))\n",
    "    return X_centered, mSST\n",
    "\n",
    "def calcMI(z1, z2):\n",
    "    eps = 10e-16\n",
    "    P = z1 @ z2.T\n",
    "    PXY = P / P.sum()\n",
    "    PXPY = np.outer(np.expand_dims(PXY.sum(1), axis=0), np.expand_dims(PXY.sum(0), axis=1))\n",
    "    ind = np.nonzero(PXY > 0)\n",
    "    MI = np.sum(PXY * np.log(eps + PXY / (eps + PXPY)))\n",
    "    return MI\n",
    "\n",
    "def calcNMI(z1, z2):\n",
    "    NMI = (2 * calcMI(z1, z2)) / (calcMI(z1, z1) + calcMI(z2, z2))\n",
    "    return NMI\n",
    "\n",
    "def ArchetypeConsistency(XC1, XC2, mSST):\n",
    "    D = squareform(pdist(np.hstack((XC1, XC2)).T, 'euclidean'))**2\n",
    "    D = D[:XC1.shape[1], XC1.shape[1]:]\n",
    "    # Greedy matching\n",
    "    i = []\n",
    "    j = []\n",
    "    v = []\n",
    "    K = XC1.shape[1]\n",
    "    for k in range(K):\n",
    "        min_index = np.unravel_index(np.argmin(D, axis=None), D.shape)\n",
    "        i.append(min_index[0])\n",
    "        j.append(min_index[1])\n",
    "        v.append(D[i[-1], j[-1]])\n",
    "        D[i[-1], :] = np.inf\n",
    "        D[:, j[-1]] = np.inf\n",
    "    consistency = 1 - np.mean(v) / mSST\n",
    "    D2 = np.abs(np.corrcoef(np.hstack((XC1, XC2)).T))\n",
    "    D2 = D2[:K, K:]\n",
    "    ISI = 1 / (2 * K * (K - 1)) * (np.sum(D2 / np.max(D2, axis=1, keepdims=True) + D2 / np.max(D2, axis=0, keepdims=True)) - 2 * K)\n",
    "    return consistency, ISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_matrices length: 5\n",
      "C_matrices[0] shape: (5842, 3)\n",
      "S_matrices length: 5\n",
      "S_matrices[0] shape: (3, 5842)\n",
      "---\n",
      "Deep AANET AA 5-run stability:\n",
      "---\n",
      "Mean NMI: 0.9834277934862339\n",
      "Mean Archetype Consistency: 0.9966966122039029\n",
      "Mean ISI: 0.49752697975207993\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Calculate metrics over the runs\n",
    "C_matrices = [to_numpy(C) for C in results['C_list']]\n",
    "print(\"C_matrices length:\", len(C_matrices))\n",
    "print(\"C_matrices[0] shape:\", C_matrices[0].shape)\n",
    "S_matrices = [to_numpy(S) for S in results['S_list']]\n",
    "print(\"S_matrices length:\", len(S_matrices))\n",
    "print(\"S_matrices[0] shape:\", S_matrices[0].shape)\n",
    "\n",
    "X_centered, mSST = preprocess(to_numpy(X))\n",
    "\n",
    "X_raw = to_numpy(X)\n",
    "\n",
    "def compute_stability_metrics(S_list, C_list, X_raw, N_RUNS):\n",
    "    \"\"\"\n",
    "    Compute pairwise stability metrics across runs.\n",
    "    \n",
    "    Returns:\n",
    "        nmi_matrix, consistency_matrix, isi_matrix\n",
    "    \"\"\"\n",
    "    X_centered, mSST_val = preprocess(X_raw)\n",
    "\n",
    "    nmi_matrix = np.zeros((N_RUNS, N_RUNS))\n",
    "    consistency_matrix = np.zeros((N_RUNS, N_RUNS))\n",
    "    isi_matrix = np.zeros((N_RUNS, N_RUNS))\n",
    "\n",
    "    for i, j in combinations(range(N_RUNS), 2):\n",
    "        S_i, S_j = S_list[i], S_list[j]\n",
    "        C_i, C_j = C_list[i], C_list[j]\n",
    "\n",
    "        nmi_matrix[i, j] = calcNMI(S_i, S_j)\n",
    "        consistency_matrix[i, j], isi_matrix[i, j] = ArchetypeConsistency(C_i, C_j, mSST_val)\n",
    "\n",
    "    # Fill symmetric and diagonal\n",
    "    nmi_matrix += nmi_matrix.T\n",
    "    consistency_matrix += consistency_matrix.T\n",
    "    isi_matrix += isi_matrix.T\n",
    "    np.fill_diagonal(nmi_matrix, 1)\n",
    "    np.fill_diagonal(consistency_matrix, 1)\n",
    "    np.fill_diagonal(isi_matrix, 1)\n",
    "\n",
    "    return nmi_matrix, consistency_matrix, isi_matrix\n",
    "\n",
    "# --- Compute for Linear AA ---\n",
    "nmi_linear, consistency_linear, isi_linear = compute_stability_metrics(S_matrices, C_matrices, X_raw, N_RUNS)\n",
    "\n",
    "print(\"---\")\n",
    "print(\"Deep AANET AA 5-run stability:\")\n",
    "print(\"---\")\n",
    "print(\"Mean NMI:\", np.mean(nmi_linear[np.triu_indices(N_RUNS, 1)]))\n",
    "print(\"Mean Archetype Consistency:\", np.mean(consistency_linear[np.triu_indices(N_RUNS, 1)]))\n",
    "print(\"Mean ISI:\", np.mean(isi_linear[np.triu_indices(N_RUNS, 1)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAQUI PARA BAIXO É EXTRA STUFF FORM THE TUTORIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archetypal_embedding = model.encode(torch.Tensor(data_digit))\n",
    "vertices_embedding = model.get_n_simplex(n=3)\n",
    "barycentric_archetypal_embedding = model.euclidean_to_barycentric(archetypal_embedding).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "scprep.plot.scatter2d(archetypal_embedding.detach().numpy(), ax=ax)\n",
    "scprep.plot.scatter2d(vertices_embedding.detach().numpy(), ax=ax, c=['red', 'blue', 'green'], s=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize average of 20 images nearest each archetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_close_to_red_archetype_idx = np.argsort(barycentric_archetypal_embedding[:, 0])[::-1][:20]\n",
    "images_close_to_red_archetype = data_digit[images_close_to_red_archetype_idx].reshape(20, 28, 28)\n",
    "plt.imshow(images_close_to_red_archetype.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_close_to_blue_archetype_idx = np.argsort(barycentric_archetypal_embedding[:, 1])[::-1][:20]\n",
    "images_close_to_blue_archetype = data_digit[images_close_to_blue_archetype_idx].reshape(20, 28, 28)\n",
    "plt.imshow(images_close_to_blue_archetype.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_close_to_green_archetype_idx = np.argsort(barycentric_archetypal_embedding[:, 2])[::-1][:20]\n",
    "images_close_to_green_archetype = data_digit[images_close_to_green_archetype_idx].reshape(20, 28, 28)\n",
    "plt.imshow(images_close_to_green_archetype.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
