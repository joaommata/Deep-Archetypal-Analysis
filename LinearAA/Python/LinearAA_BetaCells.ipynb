{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1481c3d3",
   "metadata": {},
   "source": [
    "## Running the Linear AA on the Beta Cells dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "833a2a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from src.methods.AABernoulli import Bernoulli_Archetypal_Analysis\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from src.methods.AABernoulli import Bernoulli_Archetypal_Analysis\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from src.methods.AALS import AALS \n",
    "import sys, scprep, magic, scanpy, sklearn\n",
    "from sklearn import decomposition\n",
    "import os\n",
    "from itertools import combinations\n",
    "from scipy.spatial.distance import squareform, pdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a09833",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "N_ARCHETYPES = 4\n",
    "N_RUNS = 5\n",
    "N_PROTOTYPES = 4 \n",
    "SAVE_DIR = \"results/beta_cells/AANET\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea37151",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6e17f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading single-cell dataset...\n",
      "Dataset shape: (3887, 16483)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 3887 × 16483\n",
       "    obs: 'sample'\n",
       "    var: 'human_name', 'ids'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Load Data\n",
    "print(\"Loading single-cell dataset...\")\n",
    "adata_beta_hfd = scanpy.read_h5ad('data/beta_cells_hfd.h5ad')\n",
    "\n",
    "# show size of dataset\n",
    "print(f\"Dataset shape: {adata_beta_hfd.X.shape}\")\n",
    "\n",
    "adata_beta_hfd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97ac9b",
   "metadata": {},
   "source": [
    "### Subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f1614ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsampled dataset shape: (1000, 16483)\n"
     ]
    }
   ],
   "source": [
    "# Dataset is too big, subsample for faster testing\n",
    "adata_beta_hfd = adata_beta_hfd[:1000, :]\n",
    "print(f\"Subsampled dataset shape: {adata_beta_hfd.X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe48798",
   "metadata": {},
   "source": [
    "### Apply Magic\n",
    "Result: hfd_magic → imputed gene expression matrix with fewer zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79e84b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MAGIC...\n",
      "  Running MAGIC on 1000 cells and 16483 genes.\n",
      "  Calculating graph and diffusion operator...\n",
      "    Calculating PCA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sae_env/lib/python3.11/site-packages/magic/magic.py:425: UserWarning: Input matrix contains unexpressed genes. Please remove them prior to running MAGIC.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Calculated PCA in 0.92 seconds.\n",
      "    Calculating KNN search...\n",
      "    Calculated KNN search in 0.03 seconds.\n",
      "    Calculating affinities...\n",
      "    Calculated affinities in 0.06 seconds.\n",
      "  Calculated graph and diffusion operator in 1.05 seconds.\n",
      "  Running MAGIC with `solver='exact'` on 16483-dimensional data may take a long time. Consider denoising specific genes with `genes=<list-like>` or using `solver='approximate'`.\n",
      "  Calculating imputation...\n",
      "  Calculated imputation in 0.40 seconds.\n",
      "Calculated MAGIC in 1.53 seconds.\n"
     ]
    }
   ],
   "source": [
    "hfd_magic_op = magic.MAGIC(random_state=42, t=10)\n",
    "hfd_magic = hfd_magic_op.fit_transform(adata_beta_hfd.to_df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "336b26ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic Imputed Data Shape: (1000, 16483)\n",
      "PCA Reduced Data Shape: (1000, 20)\n",
      "Normalized Data Shape: (1000, 20)\n"
     ]
    }
   ],
   "source": [
    "hfd_pc_op = decomposition.PCA(n_components=20, random_state=42)\n",
    "hfd_magic_pc = hfd_pc_op.fit_transform(hfd_magic)\n",
    "\n",
    "# Normalize for AAnet model\n",
    "hfd_magic_pc_norm = hfd_magic_pc / np.std(hfd_magic_pc[:, 0])\n",
    "\n",
    "# Print everything to debug\n",
    "print(f\"Magic Imputed Data Shape: {hfd_magic.shape}\")\n",
    "print(f\"PCA Reduced Data Shape: {hfd_magic_pc.shape}\")\n",
    "print(f\"Normalized Data Shape: {hfd_magic_pc_norm.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a4928",
   "metadata": {},
   "source": [
    "### Running the Gaussian method on the cell data\n",
    "Used 4 as n_archetypes because that's what we used in the AANet implementation, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1cbe6752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/5\n",
      "Run 2/5\n",
      "Run 3/5\n",
      "Run 4/5\n",
      "Run 5/5\n"
     ]
    }
   ],
   "source": [
    "S_list = []\n",
    "C_list = []\n",
    "L_list = []  \n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Added a transposoition to ensure final shape\n",
    "X = torch.tensor(hfd_magic_pc_norm, dtype=torch.float64).transpose(0, 1)\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    print(f\"Run {run+1}/{N_RUNS}\")\n",
    "    \n",
    "    C_run, S_run, L_run, EV = AALS(X, N_ARCHETYPES)  # Your Linear AA function\n",
    "    \n",
    "    # Append to lists\n",
    "    S_list.append(S_run.detach().cpu().numpy() if isinstance(S_run, torch.Tensor) else S_run)\n",
    "    C_list.append(C_run.detach().cpu().numpy() if isinstance(C_run, torch.Tensor) else C_run)\n",
    "    L_list.append(L_run)\n",
    "\n",
    "# Save everything\n",
    "torch.save({'C': C_list, 'S': S_list, 'L': L_list}, os.path.join(SAVE_DIR, '/Users/joaomata/Desktop/DTU/DeepLearning/ProjectDL/LinearAA/Python/results/beta_cells/AANET/beta_cells_gaussian_aa_results.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e444a53",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f8927c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Results Keys: dict_keys(['C', 'S', 'L'])\n",
      "Number of Runs Saved: 5\n",
      "Shape of C in first run: (1000, 4)\n",
      "Shape of S in first run: (4, 1000)\n",
      "Length of Losses in first run: 49\n"
     ]
    }
   ],
   "source": [
    "# Open the saved results to verify\n",
    "results = torch.load('/Users/joaomata/Desktop/DTU/DeepLearning/ProjectDL/LinearAA/Python/results/beta_cells/AANET/beta_cells_gaussian_aa_results.pth', weights_only=False)\n",
    "print(\"Saved Results Keys:\", results.keys())\n",
    "print(\"Number of Runs Saved:\", len(results['C']))\n",
    "\n",
    "# Print shapes if the first run to verify\n",
    "print(\"Shape of C in first run:\", results['C'][0].shape)\n",
    "print(\"Shape of S in first run:\", results['S'][0].shape)\n",
    "print(\"Length of Losses in first run:\", len(results['L'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327b7dd",
   "metadata": {},
   "source": [
    "# Metric Formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75eaf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        return tensor.detach().cpu().numpy()\n",
    "    return tensor\n",
    "\n",
    "def preprocess(X):\n",
    "    meanX = np.mean(X, axis=0)\n",
    "    X_centered = X - meanX\n",
    "    mSST = np.sum(np.mean(X_centered**2, axis=0))\n",
    "    return X_centered, mSST\n",
    "\n",
    "def calcMI(z1, z2):\n",
    "    eps = 10e-16\n",
    "    P = z1 @ z2.T\n",
    "    PXY = P / P.sum()\n",
    "    PXPY = np.outer(np.expand_dims(PXY.sum(1), axis=0), np.expand_dims(PXY.sum(0), axis=1))\n",
    "    ind = np.nonzero(PXY > 0)\n",
    "    MI = np.sum(PXY * np.log(eps + PXY / (eps + PXPY)))\n",
    "    return MI\n",
    "\n",
    "def calcNMI(z1, z2):\n",
    "    NMI = (2 * calcMI(z1, z2)) / (calcMI(z1, z1) + calcMI(z2, z2))\n",
    "    return NMI\n",
    "\n",
    "def ArchetypeConsistency(XC1, XC2, mSST):\n",
    "    D = squareform(pdist(np.hstack((XC1, XC2)).T, 'euclidean'))**2\n",
    "    D = D[:XC1.shape[1], XC1.shape[1]:]\n",
    "    # Greedy matching\n",
    "    i = []\n",
    "    j = []\n",
    "    v = []\n",
    "    K = XC1.shape[1]\n",
    "    for k in range(K):\n",
    "        min_index = np.unravel_index(np.argmin(D, axis=None), D.shape)\n",
    "        i.append(min_index[0])\n",
    "        j.append(min_index[1])\n",
    "        v.append(D[i[-1], j[-1]])\n",
    "        D[i[-1], :] = np.inf\n",
    "        D[:, j[-1]] = np.inf\n",
    "    consistency = 1 - np.mean(v) / mSST\n",
    "    D2 = np.abs(np.corrcoef(np.hstack((XC1, XC2)).T))\n",
    "    D2 = D2[:K, K:]\n",
    "    ISI = 1 / (2 * K * (K - 1)) * (np.sum(D2 / np.max(D2, axis=1, keepdims=True) + D2 / np.max(D2, axis=0, keepdims=True)) - 2 * K)\n",
    "    return consistency, ISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6ba9bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_matrices length: 5\n",
      "C_matrices length: 5\n",
      "---\n",
      "Linear AA 5-run stability:\n",
      "---\n",
      "Mean NMI: 0.9222568492459619\n",
      "Mean Archetype Consistency: 0.9942880621245658\n",
      "Mean ISI: 0.06661773824503898\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Calculate metrics over the runs\n",
    "C_matrices = [to_numpy(C) for C in results['C']]\n",
    "print(\"C_matrices length:\", len(C_matrices))\n",
    "S_matrices = [to_numpy(S) for S in results['S']]\n",
    "print(\"C_matrices length:\", len(C_matrices))\n",
    "X_centered, mSST = preprocess(to_numpy(X))\n",
    "\n",
    "X_raw = to_numpy(X)\n",
    "\n",
    "def compute_stability_metrics(S_list, C_list, X_raw, N_RUNS):\n",
    "    \"\"\"\n",
    "    Compute pairwise stability metrics across runs.\n",
    "    \n",
    "    Returns:\n",
    "        nmi_matrix, consistency_matrix, isi_matrix\n",
    "    \"\"\"\n",
    "    X_centered, mSST_val = preprocess(X_raw)\n",
    "\n",
    "    nmi_matrix = np.zeros((N_RUNS, N_RUNS))\n",
    "    consistency_matrix = np.zeros((N_RUNS, N_RUNS))\n",
    "    isi_matrix = np.zeros((N_RUNS, N_RUNS))\n",
    "\n",
    "    for i, j in combinations(range(N_RUNS), 2):\n",
    "        S_i, S_j = S_list[i], S_list[j]\n",
    "        C_i, C_j = C_list[i], C_list[j]\n",
    "\n",
    "        nmi_matrix[i, j] = calcNMI(S_i, S_j)\n",
    "        consistency_matrix[i, j], isi_matrix[i, j] = ArchetypeConsistency(C_i, C_j, mSST_val)\n",
    "\n",
    "    # Fill symmetric and diagonal\n",
    "    nmi_matrix += nmi_matrix.T\n",
    "    consistency_matrix += consistency_matrix.T\n",
    "    isi_matrix += isi_matrix.T\n",
    "    np.fill_diagonal(nmi_matrix, 1)\n",
    "    np.fill_diagonal(consistency_matrix, 1)\n",
    "    np.fill_diagonal(isi_matrix, 1)\n",
    "\n",
    "    return nmi_matrix, consistency_matrix, isi_matrix\n",
    "\n",
    "# --- Compute for Linear AA ---\n",
    "nmi_linear, consistency_linear, isi_linear = compute_stability_metrics(S_matrices, C_matrices, X_raw, N_RUNS)\n",
    "\n",
    "print(\"---\")\n",
    "print(\"Linear AA 5-run stability:\")\n",
    "print(\"---\")\n",
    "print(\"Mean NMI:\", np.mean(nmi_linear[np.triu_indices(N_RUNS, 1)]))\n",
    "print(\"Mean Archetype Consistency:\", np.mean(consistency_linear[np.triu_indices(N_RUNS, 1)]))\n",
    "print(\"Mean ISI:\", np.mean(isi_linear[np.triu_indices(N_RUNS, 1)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
