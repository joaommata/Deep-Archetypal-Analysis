{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header_md",
   "metadata": {},
   "source": [
    "# Archetype Analysis on **BETA CELLS**\n",
    "### Analyzing Linear AA stability across 5 runs\n",
    "\n",
    "**Dataset:** Single-Cell RNA-seq (HFD Beta Cells)\n",
    "**Pipeline:** Adapted from MNIST Analysis Pipeline\n",
    "**Goal:** Calculate consistency and stability metrics across 5 runs of Linear AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sae_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import entropy\n",
    "import umap\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "N_ARCHETYPES = 4      # k=4 (Confirmed for Beta Cells)\n",
    "N_RUNS = 4            # Number of runs in your results file\n",
    "\n",
    "# --- Paths ---\n",
    "LINEAR_AA_PATH = '/Users/joaomata/Desktop/DTU/DeepLearning/ProjectDL/LinearAA/Python/gaussian_betacells_5runs_magic/betacells_gaussian_aa_results_5runs_magic.pth'\n",
    "ADATA_PATH = '/Users/joaomata/Desktop/DTU/DeepLearning/ProjectDL/LinearAA/Python/data/beta_cells_hfd.h5ad'\n",
    "AANET_PATH = '/Users/joaomata/Desktop/DTU/DeepLearning/ProjectDL/AAnet/example_notebooks/results/beta_Cells/AAnet_singlecell_runs.pth'\n",
    "# Output folder for plots\n",
    "RESULTS_DIR = \"analysis_results/beta_cells\"\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "metric_funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Metric Functions ---\n",
    "\n",
    "def calcMI(z1, z2):\n",
    "    \"\"\"Calculates Mutual Information (MI).\"\"\"\n",
    "    eps = 1e-16\n",
    "    P = z1 @ z2.T\n",
    "    PXY = P / P.sum()\n",
    "    PXPY = np.outer(PXY.sum(1), PXY.sum(0))\n",
    "    MI = np.sum(PXY * np.log(eps + PXY / (eps + PXPY)))\n",
    "    return MI\n",
    "\n",
    "def calcNMI(z1, z2):\n",
    "    \"\"\"Calculates Normalized Mutual Information (NMI).\"\"\"\n",
    "    NMI = (2 * calcMI(z1, z2)) / (calcMI(z1, z1) + calcMI(z2, z2))\n",
    "    return NMI\n",
    "\n",
    "def preprocess(X):\n",
    "    \"\"\"Preprocessing step for mean-centering and computing mSST.\"\"\"\n",
    "    meanX = np.mean(X, axis=0)\n",
    "    X_centered = X - meanX\n",
    "    mSST = np.sum(np.mean(X_centered**2, axis=0))\n",
    "    return X_centered, mSST\n",
    "\n",
    "def ArchetypeConsistency(XC1, XC2, mSST):\n",
    "    \"\"\"Calculates Archetype Consistency and ISI between two runs.\"\"\"\n",
    "    D = squareform(pdist(np.hstack((XC1, XC2)).T, 'euclidean'))**2\n",
    "    D = D[:XC1.shape[1], XC1.shape[1]:]\n",
    "    \n",
    "    i, j, v = [], [], []\n",
    "    K = XC1.shape[1]\n",
    "    D_temp = D.copy()\n",
    "    \n",
    "    for k in range(K):\n",
    "        min_index = np.unravel_index(np.argmin(D_temp, axis=None), D_temp.shape)\n",
    "        i.append(min_index[0])\n",
    "        j.append(min_index[1])\n",
    "        v.append(D[i[-1], j[-1]])\n",
    "        D_temp[i[-1], :] = np.inf\n",
    "        D_temp[:, j[-1]] = np.inf\n",
    "    \n",
    "    consistency = 1 - np.mean(v) / mSST\n",
    "    \n",
    "    D2 = np.abs(np.corrcoef(np.hstack((XC1, XC2)).T))\n",
    "    D2 = D2[:K, K:]\n",
    "    ISI = 1 / (2 * K * (K - 1)) * (\n",
    "        np.sum(D2 / np.max(D2, axis=1, keepdims=True) + \n",
    "               D2 / np.max(D2, axis=0, keepdims=True)) - 2 * K\n",
    "    )\n",
    "    \n",
    "    return consistency, ISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "data_loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading single-cell data from /Users/joaomata/Desktop/DTU/DeepLearning/ProjectDL/LinearAA/Python/data/beta_cells_hfd.h5ad...\n",
      "Subsampled dataset shape: (1000, 16483)\n",
      "Data Loaded: 1000 cells x 16483 genes\n",
      "mSST: 636.6481\n",
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "# --- Load Single-Cell Data ---\n",
    "print(f\"Loading single-cell data from {ADATA_PATH}...\")\n",
    "\n",
    "adata = sc.read_h5ad(ADATA_PATH)\n",
    "\n",
    "\n",
    "# Dataset is too big, subsample for faster testing\n",
    "adata = adata[:1000, :]\n",
    "print(f\"Subsampled dataset shape: {adata.X.shape}\")\n",
    "\n",
    "X_dense = adata.X.toarray() if hasattr(adata.X, 'toarray') else adata.X.copy()\n",
    "X_log_normalized = sc.pp.log1p(X_dense, copy=True)\n",
    "\n",
    "N_SAMPLES = X_log_normalized.shape[0]\n",
    "N_FEATURES = X_log_normalized.shape[1]\n",
    "print(f\"Data Loaded: {N_SAMPLES} cells x {N_FEATURES} genes\")\n",
    "\n",
    "# Prepare data\n",
    "X_raw_data = X_log_normalized.astype(np.float64)\n",
    "X_centered, mSST = preprocess(X_raw_data)\n",
    "\n",
    "print(f\"mSST: {mSST:.4f}\")\n",
    "print(\"Data preparation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2445f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading runs from /Users/joaomata/Desktop/DTU/DeepLearning/ProjectDL/LinearAA/Python/gaussian_betacells_5runs_magic/betacells_gaussian_aa_results_5runs_magic.pth...\n",
      "\n",
      "--- Checking dimensions across runs ---\n",
      "Run 1: S shape (4, 1000), C shape (1000, 4), Features: 1000\n",
      "Run 2: S shape (4, 1000), C shape (1000, 4), Features: 1000\n",
      "Run 3: S shape (4, 1000), C shape (1000, 4), Features: 1000\n",
      "Run 4: S shape (4, 1000), C shape (1000, 4), Features: 1000\n",
      "\n",
      "--- Using target dimension: 1000 features ---\n",
      "This matches the subsampled data dimension: 16483\n",
      "Run 1 final: S shape (4, 1000), C shape (1000, 4)\n",
      "Run 2 final: S shape (4, 1000), C shape (1000, 4)\n",
      "Run 3 final: S shape (4, 1000), C shape (1000, 4)\n",
      "Run 4 final: S shape (4, 1000), C shape (1000, 4)\n",
      "\n",
      "✓ Successfully loaded and aligned 4 runs\n",
      "  All C matrices: (1000, 4)\n",
      "  All S matrices: (4, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Use to_numpy from previous cell (already defined)\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        return tensor.detach().cpu().numpy()\n",
    "    return tensor\n",
    "\n",
    "# --- Load Linear AA runs with dimension validation ---\n",
    "print(f\"Loading runs from {LINEAR_AA_PATH}...\")\n",
    "checkpoint = torch.load(LINEAR_AA_PATH, map_location='cpu')\n",
    "\n",
    "if 'C' not in checkpoint or 'A' not in checkpoint:\n",
    "    raise KeyError(\"The checkpoint file does not contain expected 'C' and 'A' keys.\")\n",
    "\n",
    "C_list = checkpoint['C']\n",
    "A_list = checkpoint['A']\n",
    "\n",
    "# Lists to store numpy arrays for all runs\n",
    "S_all = []\n",
    "C_all = []\n",
    "\n",
    "# First pass: identify the common dimension\n",
    "print(\"\\n--- Checking dimensions across runs ---\")\n",
    "feature_dims = []\n",
    "for run_idx in range(N_RUNS):\n",
    "    C = to_numpy(C_list[run_idx])\n",
    "    S = to_numpy(A_list[run_idx])\n",
    "    \n",
    "    # Transpose if needed\n",
    "    if S.shape[0] != N_ARCHETYPES and S.shape[1] == N_ARCHETYPES:\n",
    "        S = S.T\n",
    "    if C.shape[1] != N_ARCHETYPES and C.shape[0] == N_ARCHETYPES:\n",
    "        C = C.T\n",
    "    \n",
    "    feature_dims.append(C.shape[0])\n",
    "    print(f\"Run {run_idx+1}: S shape {S.shape}, C shape {C.shape}, Features: {C.shape[0]}\")\n",
    "\n",
    "# Find the most common dimension (or minimum to be safe)\n",
    "from collections import Counter\n",
    "dim_counts = Counter(feature_dims)\n",
    "target_dim = min(feature_dims)  # Use minimum to avoid index errors\n",
    "\n",
    "print(f\"\\n--- Using target dimension: {target_dim} features ---\")\n",
    "print(f\"This matches the subsampled data dimension: {N_FEATURES}\")\n",
    "\n",
    "# Second pass: load and align all runs to target dimension\n",
    "for run_idx in range(N_RUNS):\n",
    "    C = to_numpy(C_list[run_idx])\n",
    "    S = to_numpy(A_list[run_idx])\n",
    "    \n",
    "    # Transpose if needed\n",
    "    if S.shape[0] != N_ARCHETYPES and S.shape[1] == N_ARCHETYPES:\n",
    "        S = S.T\n",
    "    if C.shape[1] != N_ARCHETYPES and C.shape[0] == N_ARCHETYPES:\n",
    "        C = C.T\n",
    "    \n",
    "    # Truncate or select features to match target dimension\n",
    "    if C.shape[0] > target_dim:\n",
    "        print(f\"  Run {run_idx+1}: Truncating from {C.shape[0]} to {target_dim} features\")\n",
    "        C = C[:target_dim, :]\n",
    "    elif C.shape[0] < target_dim:\n",
    "        raise ValueError(f\"Run {run_idx+1} has fewer features ({C.shape[0]}) than target ({target_dim})\")\n",
    "    \n",
    "    # Similarly check S dimension matches N_SAMPLES\n",
    "    if S.shape[1] > N_SAMPLES:\n",
    "        print(f\"  Run {run_idx+1}: Truncating S from {S.shape[1]} to {N_SAMPLES} samples\")\n",
    "        S = S[:, :N_SAMPLES]\n",
    "    \n",
    "    S_all.append(S)\n",
    "    C_all.append(C)\n",
    "    \n",
    "    print(f\"Run {run_idx+1} final: S shape {S.shape}, C shape {C.shape}\")\n",
    "\n",
    "print(f\"\\n✓ Successfully loaded and aligned {N_RUNS} runs\")\n",
    "print(f\"  All C matrices: ({target_dim}, {N_ARCHETYPES})\")\n",
    "print(f\"  All S matrices: ({N_ARCHETYPES}, {N_SAMPLES})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c74263b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading AAnet results...\n",
      "✓ Loaded 5 AAnet runs\n",
      "  Example C shape: (20, 4)\n",
      "  Example S shape: (4, 1000)\n"
     ]
    }
   ],
   "source": [
    "# --- Load AAnet results ---\n",
    "print(\"\\nLoading AAnet results...\")\n",
    "\n",
    "try:\n",
    "    aanet_checkpoint = torch.load(AANET_PATH, map_location='cpu', weights_only=False)\n",
    "    \n",
    "    # Extract C and S\n",
    "    C_aanet_list = [to_numpy(c) for c in aanet_checkpoint['C_list']]\n",
    "    S_aanet_list = [to_numpy(s) for s in aanet_checkpoint['S_list']]\n",
    "\n",
    "    # Align dimensions to target_dim like Linear AA\n",
    "    C_aanet_aligned = []\n",
    "    S_aanet_aligned = []\n",
    "\n",
    "    for C, S in zip(C_aanet_list, S_aanet_list):\n",
    "        # Transpose if needed (features × archetypes)\n",
    "        if C.shape[1] != N_ARCHETYPES and C.shape[0] == N_ARCHETYPES:\n",
    "            C = C.T\n",
    "        if S.shape[0] != N_ARCHETYPES and S.shape[1] == N_ARCHETYPES:\n",
    "            S = S.T\n",
    "        \n",
    "        # Truncate C to target_dim\n",
    "        if C.shape[0] > target_dim:\n",
    "            C = C[:target_dim, :]\n",
    "        \n",
    "        # Truncate S to N_SAMPLES\n",
    "        if S.shape[1] > N_SAMPLES:\n",
    "            S = S[:, :N_SAMPLES]\n",
    "        \n",
    "        C_aanet_aligned.append(C)\n",
    "        S_aanet_aligned.append(S)\n",
    "\n",
    "    print(f\"✓ Loaded {len(C_aanet_aligned)} AAnet runs\")\n",
    "    print(f\"  Example C shape: {C_aanet_aligned[0].shape}\")\n",
    "    print(f\"  Example S shape: {S_aanet_aligned[0].shape}\")\n",
    "\n",
    "    aanet_available = True\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Could not load AAnet results: {e}\")\n",
    "    aanet_available = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "calculate_metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CALCULATING STABILITY METRICS ACROSS 4 RUNS\n",
      "============================================================\n",
      "Run 1 vs Run 2: NMI=0.9859, Consistency=0.9997, ISI=0.0759\n",
      "Run 1 vs Run 3: NMI=0.9769, Consistency=0.9997, ISI=0.0392\n",
      "Run 1 vs Run 4: NMI=0.9693, Consistency=0.9995, ISI=0.0669\n",
      "Run 2 vs Run 3: NMI=0.9645, Consistency=0.9999, ISI=0.0085\n",
      "Run 2 vs Run 4: NMI=0.9934, Consistency=1.0000, ISI=0.0094\n",
      "Run 3 vs Run 4: NMI=0.9472, Consistency=0.9998, ISI=0.0097\n",
      "\n",
      "============================================================\n",
      "AVERAGE METRICS ACROSS ALL PAIRWISE COMPARISONS\n",
      "============================================================\n",
      "Average NMI:         0.9729 ± 0.0150\n",
      "Average Consistency: 0.9998 ± 0.0002\n",
      "Average ISI:         0.0349 ± 0.0280\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate Pairwise Metrics Across All Runs ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CALCULATING STABILITY METRICS ACROSS 4 RUNS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nmi_scores = []\n",
    "consistency_scores = []\n",
    "isi_scores = []\n",
    "\n",
    "# Compare all pairs of runs\n",
    "for i in range(N_RUNS):\n",
    "    for j in range(i+1, N_RUNS):  # Fixed: was \"range(, N_RUNS)\"\n",
    "        # NMI between runs\n",
    "        nmi = calcNMI(S_all[i], S_all[j])\n",
    "        nmi_scores.append(nmi)\n",
    "        \n",
    "        # Consistency and ISI between runs\n",
    "        cons, isi = ArchetypeConsistency(C_all[i], C_all[j], mSST)\n",
    "        consistency_scores.append(cons)\n",
    "        isi_scores.append(isi)\n",
    "        \n",
    "        print(f\"Run {i+1} vs Run {j+1}: NMI={nmi:.4f}, Consistency={cons:.4f}, ISI={isi:.4f}\")\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_nmi = np.mean(nmi_scores)\n",
    "avg_consistency = np.mean(consistency_scores)\n",
    "avg_isi = np.mean(isi_scores)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"AVERAGE METRICS ACROSS ALL PAIRWISE COMPARISONS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Average NMI:         {avg_nmi:.4f} ± {np.std(nmi_scores):.4f}\")\n",
    "print(f\"Average Consistency: {avg_consistency:.4f} ± {np.std(consistency_scores):.4f}\")\n",
    "print(f\"Average ISI:         {avg_isi:.4f} ± {np.std(isi_scores):.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faafd086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CALCULATING STABILITY METRICS FOR LINEAR AA AND AANET\n",
      "============================================================\n",
      "Linear AA Run 1 vs Run 2: NMI=0.9859, Consistency=0.9997, ISI=0.0759\n",
      "Linear AA Run 1 vs Run 3: NMI=0.9769, Consistency=0.9997, ISI=0.0392\n",
      "Linear AA Run 1 vs Run 4: NMI=0.9693, Consistency=0.9995, ISI=0.0669\n",
      "Linear AA Run 2 vs Run 3: NMI=0.9645, Consistency=0.9999, ISI=0.0085\n",
      "Linear AA Run 2 vs Run 4: NMI=0.9934, Consistency=1.0000, ISI=0.0094\n",
      "Linear AA Run 3 vs Run 4: NMI=0.9472, Consistency=0.9998, ISI=0.0097\n",
      "\n",
      "============================================================\n",
      "\n",
      "Linear AA AVERAGE METRICS ACROSS ALL PAIRWISE COMPARISONS\n",
      "============================================================\n",
      "Average NMI:         0.9729 ± 0.0150\n",
      "Average Consistency: 0.9998 ± 0.0002\n",
      "Average ISI:         0.0349 ± 0.0280\n",
      "============================================================\n",
      "AAnet Run 1 vs Run 2: NMI=1.0030, Consistency=1.0000, ISI=0.8781\n",
      "AAnet Run 1 vs Run 3: NMI=1.0000, Consistency=1.0000, ISI=0.8679\n",
      "AAnet Run 1 vs Run 4: NMI=0.9997, Consistency=1.0000, ISI=0.8771\n",
      "AAnet Run 1 vs Run 5: NMI=0.9975, Consistency=1.0000, ISI=0.8733\n",
      "AAnet Run 2 vs Run 3: NMI=1.0055, Consistency=1.0000, ISI=0.8702\n",
      "AAnet Run 2 vs Run 4: NMI=1.0023, Consistency=1.0000, ISI=0.8794\n",
      "AAnet Run 2 vs Run 5: NMI=0.9999, Consistency=1.0000, ISI=0.8756\n",
      "AAnet Run 3 vs Run 4: NMI=0.9998, Consistency=1.0000, ISI=0.8692\n",
      "AAnet Run 3 vs Run 5: NMI=0.9990, Consistency=1.0000, ISI=0.8651\n",
      "AAnet Run 4 vs Run 5: NMI=0.9958, Consistency=1.0000, ISI=0.8745\n",
      "\n",
      "============================================================\n",
      "\n",
      "AAnet AVERAGE METRICS ACROSS ALL PAIRWISE COMPARISONS\n",
      "============================================================\n",
      "Average NMI:         1.0002 ± 0.0026\n",
      "Average Consistency: 1.0000 ± 0.0000\n",
      "Average ISI:         0.8730 ± 0.0045\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate Pairwise Metrics Across All Runs (Linear AA & AAnet) ---\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CALCULATING STABILITY METRICS FOR LINEAR AA AND AANET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_pairwise_metrics(C_list, S_list, mSST, method_name):\n",
    "    nmi_scores = []\n",
    "    consistency_scores = []\n",
    "    isi_scores = []\n",
    "    n_runs = len(C_list)\n",
    "    for i in range(n_runs):\n",
    "        for j in range(i+1, n_runs):\n",
    "            nmi = calcNMI(S_list[i], S_list[j])\n",
    "            nmi_scores.append(nmi)\n",
    "            cons, isi = ArchetypeConsistency(C_list[i], C_list[j], mSST)\n",
    "            consistency_scores.append(cons)\n",
    "            isi_scores.append(isi)\n",
    "            print(f\"{method_name} Run {i+1} vs Run {j+1}: NMI={nmi:.4f}, Consistency={cons:.4f}, ISI={isi:.4f}\")\n",
    "    avg_nmi = np.mean(nmi_scores)\n",
    "    avg_consistency = np.mean(consistency_scores)\n",
    "    avg_isi = np.mean(isi_scores)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"\\n{method_name} AVERAGE METRICS ACROSS ALL PAIRWISE COMPARISONS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Average NMI:         {avg_nmi:.4f} ± {np.std(nmi_scores):.4f}\")\n",
    "    print(f\"Average Consistency: {avg_consistency:.4f} ± {np.std(consistency_scores):.4f}\")\n",
    "    print(f\"Average ISI:         {avg_isi:.4f} ± {np.std(isi_scores):.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    return nmi_scores, consistency_scores, isi_scores, avg_nmi, avg_consistency, avg_isi\n",
    "\n",
    "# Linear AA metrics\n",
    "nmi_scores, consistency_scores, isi_scores, avg_nmi, avg_consistency, avg_isi = calculate_pairwise_metrics(\n",
    "    C_all, S_all, mSST, \"Linear AA\"\n",
    ")\n",
    "\n",
    "# AAnet metrics (if available)\n",
    "if aanet_available:\n",
    "    nmi_scores_aanet, consistency_scores_aanet, isi_scores_aanet, avg_nmi_aanet, avg_consistency_aanet, avg_isi_aanet = calculate_pairwise_metrics(\n",
    "        C_aanet_aligned, S_aanet_aligned, mSST, \"AAnet\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "visualization_funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization Functions ---\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        return tensor.detach().cpu().numpy()\n",
    "    return tensor\n",
    "\n",
    "def save_figure(fig, filename):\n",
    "    full_path = os.path.join(RESULTS_DIR, filename)\n",
    "    print(f\"Saving: {full_path}\")\n",
    "    fig.savefig(full_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_archetype_heatmap(C, title, save_name):\n",
    "    \"\"\"Heatmap of C matrix (Genes x Archetypes).\"\"\"\n",
    "    C = to_numpy(C)\n",
    "    fig, ax = plt.subplots(figsize=(8, 10))\n",
    "    sns.heatmap(C, cmap=\"viridis\", ax=ax, cbar_kws={'label': 'Expression'})\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel(\"Archetypes\")\n",
    "    ax.set_ylabel(\"Genes\")\n",
    "    ax.set_xticks(np.arange(C.shape[1]) + 0.5)\n",
    "    ax.set_xticklabels([f\"Arc {i+1}\" for i in range(C.shape[1])])\n",
    "    plt.tight_layout()\n",
    "    save_figure(fig, save_name)\n",
    "\n",
    "def plot_umap_assignment(X_umap, S, title, save_name):\n",
    "    \"\"\"UMAP colored by dominant archetype.\"\"\"\n",
    "    S = to_numpy(S)\n",
    "    dominant_arc = np.argmax(S.T, axis=1)\n",
    "    n_arc = S.shape[0]\n",
    "    \n",
    "    cmap_discrete = plt.cm.get_cmap('tab10', n_arc)\n",
    "    bounds = np.arange(n_arc + 1) - 0.5\n",
    "    norm = BoundaryNorm(bounds, cmap_discrete.N)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(\n",
    "        X_umap[:, 0], X_umap[:, 1],\n",
    "        c=dominant_arc, cmap=cmap_discrete, norm=norm,\n",
    "        s=10, alpha=0.6\n",
    "    )\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel('UMAP 1')\n",
    "    plt.ylabel('UMAP 2')\n",
    "    cbar = plt.colorbar(scatter, ticks=np.arange(n_arc))\n",
    "    cbar.set_ticklabels([f'Arc {i+1}' for i in range(n_arc)])\n",
    "    save_figure(fig, save_name)\n",
    "\n",
    "def plot_3d_simplex(S, title, save_name):\n",
    "    \"\"\"3D tetrahedron plot for k=4.\"\"\"\n",
    "    S = to_numpy(S)\n",
    "    k = S.shape[0]\n",
    "    \n",
    "    if k != 4:\n",
    "        print(f\"Skipping 3D Simplex: requires k=4, got k={k}\")\n",
    "        return\n",
    "    \n",
    "    S_plot = S.T\n",
    "    dominant_arc = np.argmax(S_plot, axis=1)\n",
    "    \n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    cmap_discrete = plt.cm.get_cmap('tab10', k)\n",
    "    bounds = np.arange(k + 1) - 0.5\n",
    "    norm = BoundaryNorm(bounds, cmap_discrete.N)\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        S_plot[:, 0], S_plot[:, 1], S_plot[:, 2],\n",
    "        c=dominant_arc, cmap=cmap_discrete, norm=norm,\n",
    "        s=10, alpha=0.6\n",
    "    )\n",
    "    \n",
    "    # Vertices\n",
    "    ax.scatter([1, 0, 0], [0, 1, 0], [0, 0, 1], \n",
    "              c='k', marker='D', s=100, label='Archetype Vertices')\n",
    "    \n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel('Arc 1 Weight')\n",
    "    ax.set_ylabel('Arc 2 Weight')\n",
    "    ax.set_zlabel('Arc 3 Weight')\n",
    "    ax.set_box_aspect([1, 1, 1])\n",
    "    \n",
    "    cbar = fig.colorbar(scatter, ticks=np.arange(k), pad=0.1)\n",
    "    cbar.set_ticklabels([f'Arc {i+1}' for i in range(k)])\n",
    "    \n",
    "    save_figure(fig, save_name)\n",
    "\n",
    "def plot_metric_distribution(scores, metric_name, save_name):\n",
    "    \"\"\"Box plot of metric scores across all pairwise comparisons.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    bp = ax.boxplot([scores], labels=[metric_name], patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('#4e79a7')\n",
    "    \n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title(f'{metric_name} Distribution Across Runs', fontsize=14)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add mean line\n",
    "    mean_val = np.mean(scores)\n",
    "    ax.axhline(mean_val, color='r', linestyle='--', label=f'Mean: {mean_val:.4f}')\n",
    "    ax.legend()\n",
    "    \n",
    "    save_figure(fig, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "generate_plots",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (735876729.py, line 80)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor bar, mean in zip(bars,\u001b[39m\n                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# --- Generate Visualizations ---\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "\n",
    "# Calculate UMAP (once)\n",
    "print(\"Calculating UMAP...\")\n",
    "X_umap = umap.UMAP(n_components=2, random_state=42).fit_transform(X_centered)\n",
    "\n",
    "# Use first run for detailed visualizations\n",
    "S_ref = S_all[0]\n",
    "C_ref = C_all[0]\n",
    "\n",
    "# 1. Archetype heatmap\n",
    "plot_archetype_heatmap(\n",
    "    C_ref, \n",
    "    title=\"Linear AA Archetypes (Run 0)\",\n",
    "    save_name=\"1_linear_archetypes_heatmap.png\"\n",
    ")\n",
    "\n",
    "# 2. UMAP assignment\n",
    "plot_umap_assignment(\n",
    "    X_umap, S_ref,\n",
    "    title=\"Linear AA Sample Assignment (Run 0)\",\n",
    "    save_name=\"2_linear_umap_assignment.png\"\n",
    ")\n",
    "\n",
    "# 3. 3D Simplex (if k=4)\n",
    "if N_ARCHETYPES == 4:\n",
    "    plot_3d_simplex(\n",
    "        S_ref,\n",
    "        title=\"Linear AA 3D Simplex (Run 0)\",\n",
    "        save_name=\"3_linear_3d_simplex.png\"\n",
    "    )\n",
    "\n",
    "    # --- AAnet Visualizations ---\n",
    "    if aanet_available:\n",
    "        print(\"\\nGenerating AAnet visualizations...\")\n",
    "        S_ref_aanet = S_aanet_aligned[0]\n",
    "        C_ref_aanet = C_aanet_aligned[0]\n",
    "\n",
    "        # 1. Archetype heatmap\n",
    "        plot_archetype_heatmap(\n",
    "            C_ref_aanet,\n",
    "            title=\"AAnet Archetypes (Run 0)\",\n",
    "            save_name=\"1_aanet_archetypes_heatmap.png\"\n",
    "        )\n",
    "\n",
    "        # 2. UMAP assignment\n",
    "        plot_umap_assignment(\n",
    "            X_umap, S_ref_aanet,\n",
    "            title=\"AAnet Sample Assignment (Run 0)\",\n",
    "            save_name=\"2_aanet_umap_assignment.png\"\n",
    "        )\n",
    "\n",
    "        # 3. 3D Simplex (if k=4)\n",
    "        plot_3d_simplex(\n",
    "            S_ref_aanet,\n",
    "            title=\"AAnet 3D Simplex (Run 0)\",\n",
    "            save_name=\"3_aanet_3d_simplex.png\"\n",
    "        )\n",
    "\n",
    "        # 4. Metric distributions\n",
    "        plot_metric_distribution(nmi_scores_aanet, \"NMI\", \"4_aanet_nmi_distribution.png\")\n",
    "        plot_metric_distribution(consistency_scores_aanet, \"Consistency\", \"5_aanet_consistency_distribution.png\")\n",
    "        plot_metric_distribution(isi_scores_aanet, \"ISI\", \"6_aanet_isi_distribution.png\")\n",
    "\n",
    "        # 5. Summary bar plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        metrics = ['NMI', 'Consistency', 'ISI']\n",
    "        means_aanet = [avg_nmi_aanet, avg_consistency_aanet, avg_isi_aanet]\n",
    "        stds_aanet = [np.std(nmi_scores_aanet), np.std(consistency_scores_aanet), np.std(isi_scores_aanet)]\n",
    "\n",
    "        bars = ax.bar(metrics, means_aanet, yerr=stds_aanet, capsize=10,\n",
    "                      color=['#4e79a7', '#f28e2b', '#e15759'], alpha=0.8)\n",
    "\n",
    "        ax.set_ylabel('Score', fontsize=12)\n",
    "        ax.set_title('AAnet Stability Metrics (Average ± Std)', fontsize=14, fontweight='bold')\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        ax.set_ylim([0, 1.05])\n",
    "\n",
    "        for bar, mean in zip(bars,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SAE (Python 3.11)",
   "language": "python",
   "name": "sae_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
